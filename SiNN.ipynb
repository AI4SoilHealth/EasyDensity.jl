{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e72a43-9c40-46c7-9e0b-f69c13aeca00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/mnt/tupi/HybridModeling/EasyDensity.jl`\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling EasyHybrid [61bb816a-e6af-4913-ab9e-91bff2e122e3] (cache misses: dep missing source (2))\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mattempting to remove probably stale pidfile\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  path = \"/opt/julia/compiled/v1.11/DataFrameMacros/JFuxB_R857k.ji.pidfile\"\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FileWatching.Pidfile /opt/julia-1.11.7/share/julia/stdlib/v1.11/FileWatching/src/pidfile.jl:249\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mattempting to remove probably stale pidfile\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  path = \"/opt/julia/compiled/v1.11/DataFrames/AR9oZ_R857k.ji.pidfile\"\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FileWatching.Pidfile /opt/julia-1.11.7/share/julia/stdlib/v1.11/FileWatching/src/pidfile.jl:249\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mattempting to remove probably stale pidfile\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  path = \"/opt/julia/compiled/v1.11/PrettyTables/kRdcL_R857k.ji.pidfile\"\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FileWatching.Pidfile /opt/julia-1.11.7/share/julia/stdlib/v1.11/FileWatching/src/pidfile.jl:249\u001b[39m\n",
      "WARNING: using CategoricalDistributions.classes in module MLJBase conflicts with an existing identifier.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ZygoteColorsExt [e68c091a-8ea5-5ca7-be4f-380657d4ad79] (cache misses: wrong dep version loaded (2))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ForwardDiffExt [c7e34fd8-6a5d-5aa1-8c87-78a955b9dce5] (cache misses: wrong dep version loaded (6), mismatched flags (2))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling IntervalArithmeticForwardDiffExt [ba47a815-ec9a-57c1-b718-e4e972ac9261] (cache misses: wrong dep version loaded (4), mismatched flags (2))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling SciMLBaseMakieExt [565f26a4-c902-5eae-92ad-e10714a9d9de] (cache misses: wrong dep version loaded (6), mismatched flags (2))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling EasyHybridMakie [b2ab10b6-fd29-5d20-a981-845fc6194369] (cache misses: wrong dep version loaded (4))\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DataFramesExt [9e668153-f473-5010-85ff-a85cbe3b95ea] (cache misses: wrong dep version loaded (2))\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "# Pkg.instantiate()\n",
    "using Revise\n",
    "using EasyHybrid\n",
    "using Lux\n",
    "using Optimisers\n",
    "using WGLMakie\n",
    "using Random\n",
    "using LuxCore\n",
    "using CSV, DataFrames\n",
    "using EasyHybrid.MLUtils\n",
    "using Statistics\n",
    "using Plots\n",
    "using JLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a388b348-7c67-430b-b7c5-eae3bedea740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56117, 385)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 03 - flexiable BD, both oBD and mBD will be learnt by NN\n",
    "testid = \"03_hybridNN\";\n",
    "version = \"v20251125\"\n",
    "results_dir = joinpath(@__DIR__, \"eval\");\n",
    "target_names = [:BD, :SOCconc, :CF, :SOCdensity];\n",
    "\n",
    "# input\n",
    "df = CSV.read(joinpath(@__DIR__, \"data/lucas_preprocessed_$version.csv\"), DataFrame; normalizenames=true)\n",
    "println(size(df))\n",
    "\n",
    "# scales\n",
    "scalers = Dict(\n",
    "    :SOCconc   => 0.151, # g/kg, log(x+1)*0.151\n",
    "    :CF        => 0.263, # percent, log(x+1)*0.263\n",
    "    :BD        => 0.529, # g/cm3, x*0.529\n",
    "    :SOCdensity => 0.167, # kg/m3, log(x)*0.167\n",
    ");\n",
    "\n",
    "# mechanistic model\n",
    "function SOCD_model(; SOCconc, CF, oBD, mBD)\n",
    "    ϵ = 1e-7\n",
    "\n",
    "    # invert transforms\n",
    "    soct = (exp.(SOCconc ./ scalers[:SOCconc]) .- 1) ./ 1000\n",
    "    soct = clamp.(soct, ϵ, Inf)\n",
    "\n",
    "    cft = (exp.(CF ./ scalers[:CF]) .- 1) ./ 100\n",
    "    cft = clamp.(cft, 0, 0.99)\n",
    "\n",
    "    # compute BD safely\n",
    "    som = 1.724f0 .* soct\n",
    "    denom = som .* mBD .+ (1f0 .- som) .* oBD\n",
    "    denom = clamp.(denom, ϵ, Inf)\n",
    "\n",
    "    BD = (oBD .* mBD) ./ denom\n",
    "    BD = clamp.(BD, ϵ, Inf)\n",
    "\n",
    "    # SOCdensity\n",
    "    SOCdensity = soct .* 1000 .* BD .* (1 .- cft)\n",
    "    SOCdensity = clamp.(SOCdensity, ϵ, Inf)\n",
    "\n",
    "    # scale\n",
    "    SOCdensity = log.(SOCdensity) .* scalers[:SOCdensity]\n",
    "    BD = BD .* scalers[:BD]\n",
    "\n",
    "    return (; BD, SOCconc, CF, SOCdensity, oBD, mBD)\n",
    "end\n",
    "\n",
    "\n",
    "# param bounds\n",
    "parameters = (\n",
    "    SOCconc = (0.01f0, 0.0f0, 1.0f0),   # fraction\n",
    "    CF      = (0.15f0, 0.0f0, 1.0f0),   # fraction,\n",
    "    oBD     = (0.20f0, 0.05f0, 0.40f0),  # also NN learnt, g/cm3\n",
    "    mBD     = (1.20f0, 0.75f0, 2.0f0),  # NN leanrt\n",
    ")\n",
    "\n",
    "# define param for hybrid model\n",
    "neural_param_names = [:SOCconc, :CF, :mBD, :oBD]\n",
    "# global_param_names = [:oBD]\n",
    "forcing = Symbol[]\n",
    "targets = [:BD, :SOCconc, :SOCdensity, :CF]       # SOCconc is both a param and a target\n",
    "\n",
    "# predictor\n",
    "predictors = Symbol.(names(df))[18:end-6]; # CHECK EVERY TIME \n",
    "nf = length(predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b826b7e-16ec-4111-acaa-d5ed979e8b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "# search space\n",
    "hidden_configs = [ \n",
    "    (512, 256, 128, 64, 32, 16),\n",
    "    (512, 256, 128, 64, 32), \n",
    "    (256, 128, 64, 32, 16),\n",
    "    (256, 128, 64, 32),\n",
    "    (256, 128, 64),\n",
    "    (128, 64, 32, 16),\n",
    "    (128, 64, 32),\n",
    "    (128, 64),\n",
    "    (64, 32, 16)\n",
    "];\n",
    "batch_sizes = [128, 256, 512];\n",
    "lrs = [1e-3, 5e-4, 1e-4];\n",
    "activations = [relu, tanh, swish, gelu];\n",
    "\n",
    "configs = [(h=h, bs=bs, lr=lr, act=act)\n",
    "           for h in hidden_configs\n",
    "           for bs in batch_sizes\n",
    "           for lr in lrs\n",
    "           for act in activations]\n",
    "\n",
    "println(length(configs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09afb253-94ec-4c4a-905f-477b0336bbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mThreads available: 96\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "k = 5;\n",
    "folds = make_folds(df, k = k, shuffle = true);\n",
    "rlt_list_param = Vector{DataFrame}(undef, k)\n",
    "rlt_list_pred = Vector{DataFrame}(undef, k)  \n",
    "\n",
    "@info \"Threads available: $(Threads.nthreads())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74863a89-2f80-4972-b8c6-40e51276921f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining outer fold 1 of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0001, activation=relu\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0005, activation=tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0001, activation=gelu_tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.001, activation=relu\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.001, activation=gelu_tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0001, activation=relu\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.001, activation=tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.001, activation=tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0001, activation=tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0005, activation=gelu_tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0005, activation=tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0005, activation=relu\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.001, activation=relu\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0001, activation=swish\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0005, activation=relu\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0001, activation=gelu_tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.001, activation=gelu_tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0001, activation=tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.001, activation=swish\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0005, activation=gelu_tanh\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0005, activation=swish\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.001, activation=swish\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=128, lr=0.0005, activation=swish\n",
      "Testing h=(512, 256, 128, 64, 32, 16), bs=256, lr=0.0001, activation=swish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlotting disabled.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCheck the saved output (.png, .mp4, .jld2) from training at: /mnt/tupi/HybridModeling/EasyDensity.jl/output_tmp\n"
     ]
    }
   ],
   "source": [
    "using JLD2 \n",
    "@time for test_fold in 1:k\n",
    "    @info \"Training outer fold $test_fold of $k\"\n",
    "\n",
    "    train_folds = setdiff(1:k, test_fold)\n",
    "    train_idx = findall(in(train_folds), folds)\n",
    "    train_df = df[train_idx, :]\n",
    "    test_idx  = findall(==(test_fold), folds)\n",
    "    test_df = df[test_idx, :]\n",
    "\n",
    "    # track best config for this outer fold\n",
    "    lk = ReentrantLock()\n",
    "    best_val_loss = Inf\n",
    "    best_config = nothing\n",
    "    best_result = nothing\n",
    "    best_model_path = nothing\n",
    "    results_param = DataFrame(h=String[], bs=Int[], lr=Float64[], act=String[], r2=Float64[], mse=Float64[], best_epoch=Int[], test_fold=Int[])\n",
    "\n",
    "    Threads.@threads for i in 1:(length(configs)-300)\n",
    "        try\n",
    "            cfg = configs[i]\n",
    "        \n",
    "            h  = cfg.h\n",
    "            bs = cfg.bs\n",
    "            lr = cfg.lr\n",
    "            act = cfg.act\n",
    "            println(\"Testing h=$h, bs=$bs, lr=$lr, activation=$act\")\n",
    "    \n",
    "            hm_local = constructHybridModel(\n",
    "                predictors,\n",
    "                forcing,\n",
    "                targets,\n",
    "                SOCD_model,\n",
    "                parameters,\n",
    "                neural_param_names,\n",
    "                [];\n",
    "                hidden_layers = collect(h),\n",
    "                activation = act,\n",
    "                scale_nn_outputs = true,\n",
    "                input_batchnorm = true,\n",
    "                start_from_default = true\n",
    "            )\n",
    "    \n",
    "            rlt = train(\n",
    "                hm_local, train_df, ();\n",
    "                nepochs = 200,\n",
    "                batchsize = bs,\n",
    "                opt = AdamW(lr),\n",
    "                training_loss = :mse,\n",
    "                loss_types = [:mse, :r2],\n",
    "                shuffleobs = true,\n",
    "                file_name = \"$(testid)_config$(i)_fold$(test_fold).jld2\",\n",
    "                random_seed = 42,\n",
    "                patience = 15,\n",
    "                yscale = identity,\n",
    "                monitor_names = [:oBD, :mBD],\n",
    "                agg = mean,\n",
    "                return_model = :best,\n",
    "                show_progress = false,\n",
    "                plotting = false,\n",
    "                hybrid_name = \"$(testid)_config$(i)_fold$(test_fold)\" \n",
    "            )\n",
    "    \n",
    "            lock(lk)\n",
    "            if rlt.best_loss < best_val_loss\n",
    "                best_val_loss = rlt.best_loss\n",
    "                best_config = cfg\n",
    "                best_result = rlt\n",
    "                best_model_path = \"best_model_$(testid)_config$(i)_fold$(test_fold).jld2\"\n",
    "            end\n",
    "            unlock(lk)\n",
    "        catch err\n",
    "            @error \"Thread $i crashed\" exception = err\n",
    "            @error sprint(showerror, err)\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    # register best hyper paramets\n",
    "    agg_name = Symbol(\"mean\")\n",
    "    r2s  = map(vh -> getproperty(vh, agg_name), best_result.val_history.r2)\n",
    "    mses = map(vh -> getproperty(vh, agg_name), best_result.val_history.mse)\n",
    "    best_epoch = best_result.best_epoch\n",
    "\n",
    "    local_results_param = DataFrame(\n",
    "        h = string(best_config.h),\n",
    "        bs = best_config.bs,\n",
    "        lr = best_config.lr,\n",
    "        act = string(best_config.act),\n",
    "        r2 = r2s[best_epoch],\n",
    "        mse = mses[best_epoch],\n",
    "        best_epoch = best_epoch,\n",
    "        test_fold = test_fold,\n",
    "        path = best_model_path,\n",
    "    )\n",
    "    rlt_list_param[test_fold] = local_results_param\n",
    "       \n",
    "    jld = jldopen(joinpath(\"./output_tmp\", best_model_path), \"r\")\n",
    "    best_hm = jld[\"hybridModel\"] \n",
    "    best_ps = jld[\"ps\"]      \n",
    "    best_st = jld[\"st\"]      \n",
    "    close(jld)\n",
    "    (x_test,  y_test)  = prepare_data(best_hm, test_df)\n",
    "    ŷ_test, st_test = best_hm(x_test, best_ps, LuxCore.testmode(best_st))\n",
    "    println(propertynames(ŷ_test))\n",
    "    println(propertynames(ŷ_test.parameters))\n",
    "\n",
    "    for var in [:BD, :SOCconc, :CF, :SOCdensity, :oBD, :mBD]\n",
    "        if hasproperty(ŷ_test, var)\n",
    "            val = getproperty(ŷ_test, var)\n",
    "\n",
    "            if val isa AbstractVector && length(val) == nrow(test_df)\n",
    "                test_df[!, Symbol(\"pred_\", var)] = val # per row\n",
    "\n",
    "            elseif (val isa Number) || (val isa AbstractVector && length(val) == 1)\n",
    "                test_df[!, Symbol(\"pred_\", var)] = fill(Float32(val isa AbstractVector ? first(val) : val), nrow(test_df))\n",
    "            end\n",
    "\n",
    "\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    rlt_list_pred[test_fold] = test_df\n",
    "\n",
    "end\n",
    "\n",
    "rlt_param = vcat(rlt_list_param...)\n",
    "rlt_pred = vcat(rlt_list_pred...)\n",
    "\n",
    "CSV.write(joinpath(results_dir, \"$(testid)_cv.pred_$version.csv\"), rlt_pred)\n",
    "CSV.write(joinpath(results_dir, \"$(testid)_hyperparams_$version.csv\"), rlt_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48269c4b-50f4-4955-ad14-e0c54a279e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.7",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
